{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa4de23a",
   "metadata": {},
   "source": [
    "# Provide an estimator for the slope by analytically minimizing the $ \\chi^2$\n",
    "\n",
    "### non-zero error in y\n",
    "I build a function and use $ y = ax + b + \\epsilon $, while $ \\epsilon$ is a random number from Gaussian error distribution with width $ \\sigma_{y} $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd52111",
   "metadata": {},
   "source": [
    "First, set $ f(x) = \\alpha x + \\beta $ to be the model function, that is, the function we want to fit. In this function, $\\alpha$ and $\\beta$ are possible value for $a$ and $b$. Let \n",
    "\n",
    "$$\\chi^2 = \\frac{\\sum_{i}^{n} (y_{i}-f(x_i))^2}{\\sigma_y^2} = \\frac{\\sum_{i}^{n} (y_{i}-(\\alpha x_i + \\beta))^2}{\\sigma_y^2}.$$\n",
    "\n",
    "Then, to minimize $\\chi^2$, we set $\\frac{\\partial \\chi^2}{\\partial \\alpha} = \\frac{\\partial \\chi^2}{\\partial \\beta} = 0.$\n",
    "\n",
    "It turns out, \n",
    "$$ \\alpha  = \\frac{\\sum_{i}^{N}x_i(y_i-b)}{\\sum_{i}^{N}x_i^2} \\  ; \\ \\beta = \\frac{1}{N} \\left(\\sum_{i}^{N} y_i -ax_i \\right) = \\mu_y - \\alpha \\mu_x. $$\n",
    "\n",
    "Subsituting $b$ into $a$, we get\n",
    "\n",
    "$$ \\alpha = \\frac{\\sum^{n}_{i} x_{i}(y_{i}-\\mu_{y})}{\\sum^{n}_{i} x_{i} (x_{i}-\\mu_{x})},$$\n",
    "\n",
    "$$ \\beta = \\mu_{y} - \\alpha \\mu_{x} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2d98b",
   "metadata": {},
   "source": [
    "The equation $\\alpha$ here is the estimator for slope. Also in my code, I write a function that input the value $(n, a, b, \\sigma_{y})$ and output ($\\alpha$, $\\beta$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b9aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c2960a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = number of data points\n",
    "# a, b = coefficient of model\n",
    "# sig_y = error of y\n",
    "\n",
    "def line_fit(n, a, b, sig_y): \n",
    "\n",
    "    x = np.random.uniform(0, 1, size=n)\n",
    "    epsilon = np.random.normal(0, sig_y, size=n)\n",
    "    y = a*x + b + epsilon\n",
    "    f = a*x + b\n",
    "    mu_y = sum(y)/n\n",
    "    mu_x = sum(x)/n\n",
    "    alpha = sum((y-np.ones(n)*mu_y)*x)/\\\n",
    "            sum((x-np.ones(n)*mu_x)*x)\n",
    "    beta = mu_y-a*mu_x\n",
    "    \n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b27086",
   "metadata": {},
   "source": [
    "#### Set parameters $n, a, b $ and $\\sigma_{y}$ and simulate the experiment $1000$ times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5abe1fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "a = 0.5\n",
    "b = 1\n",
    "sig_y = 0.05\n",
    "\n",
    "i = 0\n",
    "alpha_list = []\n",
    "beta_list = []\n",
    "while i < 1000:\n",
    "    result = line_fit(n, a, b, sig_y)\n",
    "    alpha_list.append(result[0])\n",
    "    beta_list.append(result[1])\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e56e572",
   "metadata": {},
   "source": [
    "This process gives the list of $\\alpha$ and $\\beta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3b3fc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3761055187486882, 0.980605718145883)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_list[0], beta_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d847175",
   "metadata": {},
   "source": [
    "#### To see if the estimator is biased. \n",
    "\n",
    "That is, whether $<\\alpha> = a$ and $<\\beta> = b$?\n",
    "\n",
    "First, caculate the expectation value of two estimators. I round the number to three decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ecd83d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.502 1.0\n"
     ]
    }
   ],
   "source": [
    "expectation_of_alpha = sum(alpha_list)/len(alpha_list)\n",
    "expectation_of_beta = sum(beta_list)/len(beta_list)\n",
    "\n",
    "print(round(expectation_of_alpha, 3), round(expectation_of_beta, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb03155d",
   "metadata": {},
   "source": [
    "Cacualte the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dccad12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias of estimator alpha = 0.002\n",
      "bias of estimator beta = 0.000\n"
     ]
    }
   ],
   "source": [
    "print('bias of estimator alpha = %.3f' % (expectation_of_alpha - a))\n",
    "print('bias of estimator beta = %.3f' % (expectation_of_beta - b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efb56af",
   "metadata": {},
   "source": [
    "### Now add an error in x\n",
    "\n",
    "Just like we do to $y$, in this case, $x_{i}{'} = x_{i} + \\epsilon_{x}$. $\\epsilon_{x}$ is a Gaussian error with width $\\sigma_{x}$. \n",
    "\n",
    "The funation is almost the same, and the only difference is the change of $x_{i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5ca0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_fit_with_error(n, a, b, sig_y, sig_x):\n",
    "    epsilon_y = np.random.normal(0, sig_y, size=n)\n",
    "    epsilon_x = np.random.normal(0, sig_x, size=n)\n",
    "    tx = np.random.uniform(0, 1, size=n)\n",
    "    x = tx + epsilon_x\n",
    "    y = a*x + b + epsilon_y\n",
    "    f = a*x + b\n",
    "    mu_y = sum(y)/n\n",
    "    mu_x = sum(x)/n\n",
    "    \n",
    "    alpha = sum((y-np.ones(n)*mu_y)*x)/sum((x-np.ones(n)*mu_x)*x)\n",
    "    beta = mu_y-alpha*mu_x\n",
    "\n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46768d32",
   "metadata": {},
   "source": [
    "#### Set parameters $n, a, b $ , $\\sigma_{y}$ $\\sigma_{x}$  and simulate the experiment $1000$ times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d643c11",
   "metadata": {},
   "source": [
    "Set $a = 0.5, b = 1, \\sigma_{x} = 0.05, \\sigma_{y} = 0.05$ and run the experiment 1000 times to see the expectation value of $\\alpha$ and $\\beta$. Then caculate the bias of each esitmator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db38c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.502 0.999\n",
      "bias of estimator alpha = 0.002\n",
      "bias of estimator beta = -0.001\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "a = 0.5\n",
    "b = 1\n",
    "sig_y = 0.05\n",
    "sig_x = 0.05\n",
    "\n",
    "i = 0\n",
    "alpha_list = []\n",
    "beta_list = []\n",
    "while i < 1000:\n",
    "    result = line_fit_with_error(n, a, b, sig_y, sig_x)\n",
    "    alpha_list.append(result[0])\n",
    "    beta_list.append(result[1])\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "expectation_of_alpha = sum(alpha_list)/len(alpha_list)\n",
    "expectation_of_beta = sum(beta_list)/len(beta_list)\n",
    "\n",
    "print(round(expectation_of_alpha, 3), round(expectation_of_beta, 3))\n",
    "print('bias of estimator alpha = %.3f' % (expectation_of_alpha - a))\n",
    "print('bias of estimator beta = %.3f' % (expectation_of_beta - b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6336d0",
   "metadata": {},
   "source": [
    "#### Increase the error of y and x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a6da6b",
   "metadata": {},
   "source": [
    "Set $a = 0.5, b = 1, \\sigma_{x} = 0.2, \\sigma_{y} = 0.2$ and run the experiment 1000 times to see the expectation value of $\\alpha$ and $\\beta$. Then caculate the bias of each esitmator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c8baa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509 0.997\n",
      "bias of estimator alpha = 0.009\n",
      "bias of estimator beta = -0.003\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "a = 0.5\n",
    "b = 1\n",
    "sig_y = 0.2\n",
    "sig_x = 0.2\n",
    "\n",
    "i = 0\n",
    "alpha_list = []\n",
    "beta_list = []\n",
    "while i < 1000:\n",
    "    result = line_fit_with_error(n, a, b, sig_y, sig_x)\n",
    "    alpha_list.append(result[0])\n",
    "    beta_list.append(result[1])\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "expectation_of_alpha = sum(alpha_list)/len(alpha_list)\n",
    "expectation_of_beta = sum(beta_list)/len(beta_list)\n",
    "\n",
    "print(round(expectation_of_alpha, 3), round(expectation_of_beta, 3))\n",
    "print('bias of estimator alpha = %.3f' % (expectation_of_alpha - a))\n",
    "print('bias of estimator beta = %.3f' % (expectation_of_beta - b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33dc383",
   "metadata": {},
   "source": [
    "#### What if we change the size of data set? What is the difference between small number of data points and large number of data points?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c626ada9",
   "metadata": {},
   "source": [
    "Change the value of $n$. Make $n = 10, 100, 1000$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f45442ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498 1.004\n",
      "bias of estimator alpha (n = 10) = -0.002\n",
      "bias of estimator beta (n = 10) = 0.004\n",
      "0.5 1.0\n",
      "bias of estimator alpha (n = 100) = -0.000\n",
      "bias of estimator beta (n = 100) = 0.000\n",
      "0.499 1.0\n",
      "bias of estimator alpha (n = 1000) = -0.001\n",
      "bias of estimator beta (n = 1000) = 0.000\n"
     ]
    }
   ],
   "source": [
    "a = 0.5\n",
    "b = 1\n",
    "sig_y = 0.2\n",
    "sig_x = 0.2\n",
    "\n",
    "alpha1_list = []\n",
    "beta1_list = []\n",
    "alpha2_list = []\n",
    "beta2_list = []\n",
    "alpha3_list = []\n",
    "beta3_list = []\n",
    "\n",
    "i = 0\n",
    "while i < 1000:\n",
    "    result1 = line_fit_with_error(5, a, b, sig_y, sig_x)\n",
    "    result2 = line_fit_with_error(100, a, b, sig_y, sig_x)\n",
    "    result3 = line_fit_with_error(1000, a, b, sig_y, sig_x)\n",
    "    alpha1_list.append(result1[0])\n",
    "    beta1_list.append(result1[1])\n",
    "    alpha2_list.append(result2[0])\n",
    "    beta2_list.append(result2[1])\n",
    "    alpha3_list.append(result3[0])\n",
    "    beta3_list.append(result3[1])\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "expectation_of_alpha1 = sum(alpha1_list)/len(alpha1_list)\n",
    "expectation_of_beta1 = sum(beta1_list)/len(beta1_list)\n",
    "expectation_of_alpha2 = sum(alpha2_list)/len(alpha2_list)\n",
    "expectation_of_beta2 = sum(beta2_list)/len(beta2_list)\n",
    "expectation_of_alpha3 = sum(alpha3_list)/len(alpha3_list)\n",
    "expectation_of_beta3 = sum(beta3_list)/len(beta3_list)\n",
    "\n",
    "print(round(expectation_of_alpha1, 3), round(expectation_of_beta1, 3))\n",
    "print('bias of estimator alpha (n = 10) = %.3f' % (expectation_of_alpha1 - a))\n",
    "print('bias of estimator beta (n = 10) = %.3f' % (expectation_of_beta1 - b))\n",
    "\n",
    "print(round(expectation_of_alpha2, 3), round(expectation_of_beta2, 3))\n",
    "print('bias of estimator alpha (n = 100) = %.3f' % (expectation_of_alpha2 - a))\n",
    "print('bias of estimator beta (n = 100) = %.3f' % (expectation_of_beta2 - b))\n",
    "\n",
    "print(round(expectation_of_alpha3, 3), round(expectation_of_beta3, 3))\n",
    "print('bias of estimator alpha (n = 1000) = %.3f' % (expectation_of_alpha3 - a))\n",
    "print('bias of estimator beta (n = 1000) = %.3f' % (expectation_of_beta3 - b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfd8898",
   "metadata": {},
   "source": [
    "Monte-Carlo method uses random variables to caculate the results. If we only get a few data point, the result might lost its reliability. From the definition of consistency, as $n$ goes larger, the estimator should come closer to the ture value.\n",
    "\n",
    "As for the bias, $<\\hat{\\theta}> = \\theta$ also holds if $x$ has error. That is, the estimator we derived from $\\chi^2$ is non-biased in this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1750d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
